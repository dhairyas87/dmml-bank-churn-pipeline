{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2a95ea-d8c6-4241-97b4-fe3adf4ec356",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/Bank_Churn_Full_Report.docx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 134\u001b[0m\n\u001b[1;32m    129\u001b[0m     doc\u001b[38;5;241m.\u001b[39madd_paragraph(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline graph stored as DOT file at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morchestor_dot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# ----------------------\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Save Document\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# ----------------------\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m doc\u001b[38;5;241m.\u001b[39msave(output_docx)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Word report generated at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_docx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/docx/document.py:204\u001b[0m, in \u001b[0;36mDocument.save\u001b[0;34m(self, path_or_stream)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, path_or_stream: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m IO[\u001b[38;5;28mbytes\u001b[39m]):\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save this document to `path_or_stream`.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    `path_or_stream` can be either a path to a filesystem location (a string) or a\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    file-like object.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_part\u001b[38;5;241m.\u001b[39msave(path_or_stream)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/docx/parts/document.py:114\u001b[0m, in \u001b[0;36mDocumentPart.save\u001b[0;34m(self, path_or_stream)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, path_or_stream: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m IO[\u001b[38;5;28mbytes\u001b[39m]):\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save this document to `path_or_stream`, which can be either a path to a\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    filesystem location (a string) or a file-like object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpackage\u001b[38;5;241m.\u001b[39msave(path_or_stream)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/docx/opc/package.py:166\u001b[0m, in \u001b[0;36mOpcPackage.save\u001b[0;34m(self, pkg_file)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts:\n\u001b[1;32m    165\u001b[0m     part\u001b[38;5;241m.\u001b[39mbefore_marshal()\n\u001b[0;32m--> 166\u001b[0m PackageWriter\u001b[38;5;241m.\u001b[39mwrite(pkg_file, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/docx/opc/pkgwriter.py:34\u001b[0m, in \u001b[0;36mPackageWriter.write\u001b[0;34m(pkg_file, pkg_rels, parts)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(pkg_file, pkg_rels, parts):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write a physical package (.pptx file) to `pkg_file` containing `pkg_rels` and\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    `parts` and a content types stream based on the content types of the parts.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     phys_writer \u001b[38;5;241m=\u001b[39m PhysPkgWriter(pkg_file)\n\u001b[1;32m     35\u001b[0m     PackageWriter\u001b[38;5;241m.\u001b[39m_write_content_types_stream(phys_writer, parts)\n\u001b[1;32m     36\u001b[0m     PackageWriter\u001b[38;5;241m.\u001b[39m_write_pkg_rels(phys_writer, pkg_rels)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/docx/opc/phys_pkg.py:109\u001b[0m, in \u001b[0;36m_ZipPkgWriter.__init__\u001b[0;34m(self, pkg_file)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pkg_file):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_ZipPkgWriter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zipf \u001b[38;5;241m=\u001b[39m ZipFile(pkg_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, compression\u001b[38;5;241m=\u001b[39mZIP_DEFLATED)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/zipfile/__init__.py:1331\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(file, filemode)\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/Bank_Churn_Full_Report.docx'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "# ----------------------\n",
    "# Config\n",
    "# ----------------------\n",
    "base_path = \"results\"\n",
    "output_docx = \"results/Bank_Churn_Full_Report.docx\"\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading(\"Bank Customer Churn Prediction - Full Pipeline Report\", 0)\n",
    "\n",
    "# ----------------------\n",
    "# Section 1: Problem Formulation\n",
    "# ----------------------\n",
    "doc.add_heading(\"Problem Formulation\", level=1)\n",
    "doc.add_paragraph(\n",
    "    \"The objective of this project is to predict whether a bank customer will churn \"\n",
    "    \"(leave the bank) based on demographic, financial, and transactional attributes. \"\n",
    "    \"This involves building a machine learning pipeline covering data ingestion, EDA, \"\n",
    "    \"feature engineering, model training, and evaluation.\"\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# Section 2: EDA Summary\n",
    "# ----------------------\n",
    "eda_report = os.path.join(base_path, \"eda/eda_report.pdf\")\n",
    "summary_csv = os.path.join(base_path, \"eda/summary_statistics.csv\")\n",
    "\n",
    "doc.add_heading(\"Exploratory Data Analysis\", level=1)\n",
    "if os.path.exists(eda_report):\n",
    "    doc.add_paragraph(\"A full PDF EDA report was generated and can be found at:\")\n",
    "    doc.add_paragraph(eda_report)\n",
    "\n",
    "if os.path.exists(summary_csv):\n",
    "    df_summary = pd.read_csv(summary_csv)\n",
    "    doc.add_heading(\"Summary Statistics\", level=2)\n",
    "    table = doc.add_table(rows=1, cols=len(df_summary.columns))\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    for i, col in enumerate(df_summary.columns):\n",
    "        hdr_cells[i].text = col\n",
    "\n",
    "    for _, row in df_summary.iterrows():\n",
    "        row_cells = table.add_row().cells\n",
    "        for i, col in enumerate(df_summary.columns):\n",
    "            row_cells[i].text = str(row[col])\n",
    "\n",
    "# ----------------------\n",
    "# Section 3: Feature Store\n",
    "# ----------------------\n",
    "doc.add_heading(\"Feature Store\", level=1)\n",
    "feature_doc = os.path.join(base_path, \"feature_store/feature_store_doc.txt\")\n",
    "if os.path.exists(feature_doc):\n",
    "    with open(feature_doc, \"r\") as f:\n",
    "        doc.add_paragraph(f.read())\n",
    "\n",
    "# ----------------------\n",
    "# Section 4: Data Versioning\n",
    "# ----------------------\n",
    "doc.add_heading(\"Data Versioning\", level=1)\n",
    "raw_data = os.path.join(base_path, \"data/raw/churn.csv\")\n",
    "transformed_data = os.path.join(base_path, \"data/transformed/churn_transformed.csv\")\n",
    "\n",
    "if os.path.exists(raw_data):\n",
    "    doc.add_paragraph(f\"Raw dataset stored at: {raw_data}\")\n",
    "if os.path.exists(transformed_data):\n",
    "    doc.add_paragraph(f\"Transformed dataset stored at: {transformed_data}\")\n",
    "\n",
    "# ----------------------\n",
    "# Section 5: Models and Results\n",
    "# ----------------------\n",
    "doc.add_heading(\"Model Training and Evaluation\", level=1)\n",
    "\n",
    "results_file = os.path.join(base_path, \"models/model_results.txt\")\n",
    "if os.path.exists(results_file):\n",
    "    with open(results_file, \"r\") as f:\n",
    "        results_text = f.read()\n",
    "    doc.add_paragraph(\"Results Summary:\")\n",
    "    doc.add_paragraph(results_text)\n",
    "\n",
    "# Handle model versions JSON\n",
    "model_versions = os.path.join(base_path, \"models/model_versions.json\")\n",
    "best_model = None\n",
    "best_score = -1\n",
    "\n",
    "if os.path.exists(model_versions):\n",
    "    doc.add_heading(\"Model Versions\", level=2)\n",
    "    with open(model_versions, \"r\") as f:\n",
    "        versions = json.load(f)\n",
    "    \n",
    "    if isinstance(versions, dict):\n",
    "        for key, val in versions.items():\n",
    "            doc.add_paragraph(f\"{key}: {val}\")\n",
    "            # Pick best model if Accuracy/F1 available\n",
    "            if isinstance(val, dict):\n",
    "                score = val.get(\"Accuracy\") or val.get(\"F1\") or 0\n",
    "                if score > best_score:\n",
    "                    best_score, best_model = score, key\n",
    "    elif isinstance(versions, list):\n",
    "        for i, entry in enumerate(versions, start=1):\n",
    "            doc.add_heading(f\"Model {i}\", level=3)\n",
    "            if isinstance(entry, dict):\n",
    "                for k, v in entry.items():\n",
    "                    doc.add_paragraph(f\"{k}: {v}\")\n",
    "                score = entry.get(\"Accuracy\") or entry.get(\"F1\") or 0\n",
    "                if score > best_score:\n",
    "                    best_score, best_model = score, f\"Model {i}\"\n",
    "            else:\n",
    "                doc.add_paragraph(str(entry))\n",
    "    else:\n",
    "        doc.add_paragraph(str(versions))\n",
    "\n",
    "    if best_model:\n",
    "        doc.add_heading(\"Best Model Summary\", level=2)\n",
    "        doc.add_paragraph(\n",
    "            f\"The best performing model is **{best_model}** \"\n",
    "            f\"with a score of {best_score:.4f}.\"\n",
    "        )\n",
    "\n",
    "# ----------------------\n",
    "# Section 6: Pipeline Orchestration\n",
    "# ----------------------\n",
    "doc.add_heading(\"Pipeline Orchestration\", level=1)\n",
    "orchestor_dot = os.path.join(base_path, \"visualization/orchestor.dot\")\n",
    "if os.path.exists(orchestor_dot):\n",
    "    doc.add_paragraph(f\"Pipeline graph stored as DOT file at: {orchestor_dot}\")\n",
    "\n",
    "# ----------------------\n",
    "# Save Document\n",
    "# ----------------------\n",
    "doc.save(output_docx)\n",
    "print(f\"✅ Word report generated at: {output_docx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1914dea8-95b9-4aca-b00c-f6fb0126ac0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (4.14.1)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a118a55-9fe9-46a7-8507-96bda15bcbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
