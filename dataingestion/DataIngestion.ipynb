{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eebdc5bd-2e46-41af-8033-b9829ef6db9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 08:35:21,059 [INFO] === Ingestion cycle started at 2025-08-24 08:35:21.059196 ===\n",
      "2025-08-24 08:35:21,060 [INFO] === Loading from Microsoft data set ===\n",
      "2025-08-24 08:35:21,060 [INFO] [CSV_Source] CSV data loading from https://synapseaisolutionsa.z13.web.core.windows.net/data/bankcustomerchurn/churn.csv\n",
      "2025-08-24 08:35:23,121 [INFO] [CSV_Source] CSV data loaded with shape (10000, 14)\n",
      "2025-08-24 08:35:23,122 [INFO] Kaggle dataset for customer churn\n",
      "2025-08-24 08:35:23,123 [INFO] [CSV_Source] CSV data loading from /Users/dhairyas87/DMML_Machine_Learning_Pipeline/dataingestion/Customer_Churn_kaggle.csv\n",
      "2025-08-24 08:35:23,131 [INFO] [CSV_Source] CSV data loaded with shape (3150, 16)\n",
      "2025-08-24 08:35:23,131 [INFO] CSV shape: (10000, 14)\n",
      "2025-08-24 08:35:23,132 [INFO] === Ingestion cycle completed ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Logging Setup\n",
    "# ---------------------\n",
    "log_file = \"ingestion_job_results.log\"\n",
    "\n",
    "logger = logging.getLogger(\"IngestionLoggerResult\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Console handler\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# File handler with rotation (5 MB per file, keep last 3 files)\n",
    "file_handler = RotatingFileHandler(log_file, maxBytes=5_000_000, backupCount=3)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "console_handler.setFormatter(formatter)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# ---------------------\n",
    "# Ingestion functions\n",
    "# ---------------------\n",
    "def load_csv(path_or_url: str, source: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        logger.info(f\"[{source}] CSV data loading from {path_or_url}\")\n",
    "        df = pd.read_csv(path_or_url)\n",
    "        logger.info(f\"[{source}] CSV data loaded with shape {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{source}] CSV ingestion failed: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_api(endpoint: str, params=None, headers=None):\n",
    "    try:\n",
    "        logger.info(f\"[API] Fetching data from {endpoint}\")\n",
    "        response = requests.get(endpoint, params=params, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        logger.info(f\"[API] Data fetched with {len(data)} records\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[API] Ingestion failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def load_db(query: str, connection_string: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        logger.info(f\"[DB] Executing query on {connection_string}\")\n",
    "        engine = sqlalchemy.create_engine(connection_string)\n",
    "        df = pd.read_sql(query, engine)\n",
    "        logger.info(f\"[DB] Data loaded with shape {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[DB] Ingestion failed: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ---------------------\n",
    "# Retry wrapper\n",
    "# ---------------------\n",
    "def safe_ingest(func, retries=3, delay=5, *args, **kwargs):\n",
    "    \"\"\"Retry ingestion function if it fails, with backoff delay.\"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        result = func(*args, **kwargs)\n",
    "        if isinstance(result, pd.DataFrame) and not result.empty:\n",
    "            return result\n",
    "        if isinstance(result, list) and len(result) > 0:\n",
    "            return result\n",
    "\n",
    "        attempt += 1\n",
    "        logger.warning(f\"Retry {attempt}/{retries} after failure. Waiting {delay} sec...\")\n",
    "        time.sleep(delay)\n",
    "    logger.error(f\"All {retries} attempts failed for {func.__name__}\")\n",
    "    return pd.DataFrame() if func.__name__ != \"load_api\" else []\n",
    "\n",
    "# ---------------------\n",
    "# Scheduler\n",
    "# ---------------------\n",
    "def run_periodic_ingestion(interval_seconds=60):\n",
    "    \"\"\"Run ingestion periodically at fixed interval.\"\"\"\n",
    "    while True:\n",
    "        logger.info(f\"=== Ingestion cycle started at {datetime.now()} ===\")\n",
    "\n",
    "        # Example sources (replace with real)\n",
    "        logger.info(f\"=== Loading from Microsoft data set ===\")\n",
    "        df_csv = safe_ingest(load_csv, 3, 5, \"https://synapseaisolutionsa.z13.web.core.windows.net/data/bankcustomerchurn/churn.csv\", \"CSV_Source\")\n",
    "        \n",
    "\n",
    "\n",
    "    # Download latest version\n",
    "        current_directory = os.getcwd()\n",
    "        path = current_directory+ \"/Customer_Churn_kaggle.csv\"\n",
    "\n",
    "        logger.info(\"Kaggle dataset for customer churn\")\n",
    "        safe_ingest(load_csv, 3, 5, path, \"CSV_Source\")\n",
    "        # For monitoring, log sizes\n",
    "        logger.info(f\"CSV shape: {df_csv.shape if isinstance(df_csv, pd.DataFrame) else 'N/A'}\")\n",
    "       \n",
    "\n",
    "        logger.info(\"=== Ingestion cycle completed ===\\n\")\n",
    "        time.sleep(interval_seconds)  # wait before next cycle\n",
    "        return df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ffdb49-1662-4101-a675-d2e7a38d4877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
