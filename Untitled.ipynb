{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca2a95ea-d8c6-4241-97b4-fe3adf4ec356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Word report generated at: results/Bank_Churn_Full_Report.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "# ----------------------\n",
    "# Config\n",
    "# ----------------------\n",
    "base_path = \"results\"\n",
    "output_docx = \"results/Bank_Churn_Full_Report.docx\"\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading(\"Bank Customer Churn Prediction - Full Pipeline Report\", 0)\n",
    "\n",
    "# ----------------------\n",
    "# Section 1: Problem Formulation\n",
    "# ----------------------\n",
    "doc.add_heading(\"Problem Formulation\", level=1)\n",
    "doc.add_paragraph(\n",
    "    \"The objective of this project is to predict whether a bank customer will churn \"\n",
    "    \"(leave the bank) based on demographic, financial, and transactional attributes. \"\n",
    "    \"This involves building a machine learning pipeline covering data ingestion, EDA, \"\n",
    "    \"feature engineering, model training, and evaluation.\"\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# Section 2: EDA Summary\n",
    "# ----------------------\n",
    "eda_report = os.path.join(base_path, \"eda/eda_report.pdf\")\n",
    "summary_csv = os.path.join(base_path, \"eda/summary_statistics.csv\")\n",
    "\n",
    "doc.add_heading(\"Exploratory Data Analysis\", level=1)\n",
    "if os.path.exists(eda_report):\n",
    "    doc.add_paragraph(\"A full PDF EDA report was generated and can be found at:\")\n",
    "    doc.add_paragraph(eda_report)\n",
    "\n",
    "if os.path.exists(summary_csv):\n",
    "    df_summary = pd.read_csv(summary_csv)\n",
    "    doc.add_heading(\"Summary Statistics\", level=2)\n",
    "    table = doc.add_table(rows=1, cols=len(df_summary.columns))\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    for i, col in enumerate(df_summary.columns):\n",
    "        hdr_cells[i].text = col\n",
    "\n",
    "    for _, row in df_summary.iterrows():\n",
    "        row_cells = table.add_row().cells\n",
    "        for i, col in enumerate(df_summary.columns):\n",
    "            row_cells[i].text = str(row[col])\n",
    "\n",
    "# ----------------------\n",
    "# Section 3: Feature Store\n",
    "# ----------------------\n",
    "doc.add_heading(\"Feature Store\", level=1)\n",
    "feature_doc = os.path.join(base_path, \"feature_store/feature_store_doc.txt\")\n",
    "if os.path.exists(feature_doc):\n",
    "    with open(feature_doc, \"r\") as f:\n",
    "        doc.add_paragraph(f.read())\n",
    "\n",
    "# ----------------------\n",
    "# Section 4: Data Versioning\n",
    "# ----------------------\n",
    "doc.add_heading(\"Data Versioning\", level=1)\n",
    "raw_data = os.path.join(base_path, \"data/raw/churn.csv\")\n",
    "transformed_data = os.path.join(base_path, \"data/transformed/churn_transformed.csv\")\n",
    "\n",
    "if os.path.exists(raw_data):\n",
    "    doc.add_paragraph(f\"Raw dataset stored at: {raw_data}\")\n",
    "if os.path.exists(transformed_data):\n",
    "    doc.add_paragraph(f\"Transformed dataset stored at: {transformed_data}\")\n",
    "\n",
    "# ----------------------\n",
    "# Section 5: Models and Results\n",
    "# ----------------------\n",
    "doc.add_heading(\"Model Training and Evaluation\", level=1)\n",
    "\n",
    "results_file = os.path.join(base_path, \"models/model_results.txt\")\n",
    "if os.path.exists(results_file):\n",
    "    with open(results_file, \"r\") as f:\n",
    "        results_text = f.read()\n",
    "    doc.add_paragraph(\"Results Summary:\")\n",
    "    doc.add_paragraph(results_text)\n",
    "\n",
    "# Handle model versions JSON\n",
    "model_versions = os.path.join(base_path, \"models/model_versions.json\")\n",
    "best_model = None\n",
    "best_score = -1\n",
    "\n",
    "if os.path.exists(model_versions):\n",
    "    doc.add_heading(\"Model Versions\", level=2)\n",
    "    with open(model_versions, \"r\") as f:\n",
    "        versions = json.load(f)\n",
    "    \n",
    "    if isinstance(versions, dict):\n",
    "        for key, val in versions.items():\n",
    "            doc.add_paragraph(f\"{key}: {val}\")\n",
    "            # Pick best model if Accuracy/F1 available\n",
    "            if isinstance(val, dict):\n",
    "                score = val.get(\"Accuracy\") or val.get(\"F1\") or 0\n",
    "                if score > best_score:\n",
    "                    best_score, best_model = score, key\n",
    "    elif isinstance(versions, list):\n",
    "        for i, entry in enumerate(versions, start=1):\n",
    "            doc.add_heading(f\"Model {i}\", level=3)\n",
    "            if isinstance(entry, dict):\n",
    "                for k, v in entry.items():\n",
    "                    doc.add_paragraph(f\"{k}: {v}\")\n",
    "                score = entry.get(\"Accuracy\") or entry.get(\"F1\") or 0\n",
    "                if score > best_score:\n",
    "                    best_score, best_model = score, f\"Model {i}\"\n",
    "            else:\n",
    "                doc.add_paragraph(str(entry))\n",
    "    else:\n",
    "        doc.add_paragraph(str(versions))\n",
    "\n",
    "    if best_model:\n",
    "        doc.add_heading(\"Best Model Summary\", level=2)\n",
    "        doc.add_paragraph(\n",
    "            f\"The best performing model is **{best_model}** \"\n",
    "            f\"with a score of {best_score:.4f}.\"\n",
    "        )\n",
    "\n",
    "# ----------------------\n",
    "# Section 6: Pipeline Orchestration\n",
    "# ----------------------\n",
    "doc.add_heading(\"Pipeline Orchestration\", level=1)\n",
    "orchestor_dot = os.path.join(base_path, \"visualization/orchestor.dot\")\n",
    "if os.path.exists(orchestor_dot):\n",
    "    doc.add_paragraph(f\"Pipeline graph stored as DOT file at: {orchestor_dot}\")\n",
    "\n",
    "# ----------------------\n",
    "# Save Document\n",
    "# ----------------------\n",
    "doc.save(output_docx)\n",
    "print(f\"✅ Word report generated at: {output_docx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1914dea8-95b9-4aca-b00c-f6fb0126ac0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in /opt/anaconda3/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (4.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a118a55-9fe9-46a7-8507-96bda15bcbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
