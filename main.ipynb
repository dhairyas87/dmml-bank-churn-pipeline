{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b88a5a-fc4d-44d5-a4bf-eba3c109f024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 18:53:47,528 [INFO] CSV data loading from Path with source https://synapseaisolutionsa.z13.web.core.windows.net/data/bankcustomerchurn/churn.csv\n",
      "2025-08-23 18:54:01,649 [INFO] CSV data loaded with shape (10000, 14)\n",
      "2025-08-23 18:54:01,702 [INFO] CSV data stored at datastorage/csv/year=2025/month=08/day=23/csv_DataStorage.csv\n",
      "2025-08-23 18:54:01,702 [INFO] ===== Validation started =====\n",
      "2025-08-23 18:54:01,702 [INFO] Starting check: RowNumber sequence\n",
      "2025-08-23 18:54:01,703 [INFO] Completed check: RowNumber sequence\n",
      "2025-08-23 18:54:01,703 [INFO] Starting check: CustomerId uniqueness\n",
      "2025-08-23 18:54:01,704 [INFO] Completed check: CustomerId uniqueness\n",
      "2025-08-23 18:54:01,704 [INFO] Starting check: CreditScore validity\n",
      "2025-08-23 18:54:01,704 [INFO] Completed check: CreditScore validity\n",
      "2025-08-23 18:54:01,705 [INFO] Starting check: Geography validity\n",
      "2025-08-23 18:54:01,705 [INFO] Completed check: Geography validity\n",
      "2025-08-23 18:54:01,706 [INFO] Starting check: Gender validity\n",
      "2025-08-23 18:54:01,706 [INFO] Completed check: Gender validity\n",
      "2025-08-23 18:54:01,706 [INFO] Starting check: Age range\n",
      "2025-08-23 18:54:01,707 [INFO] Completed check: Age range\n",
      "2025-08-23 18:54:01,707 [INFO] Starting check: Tenure range\n",
      "2025-08-23 18:54:01,708 [INFO] Completed check: Tenure range\n",
      "2025-08-23 18:54:01,709 [INFO] Starting check: Balance non-negative\n",
      "2025-08-23 18:54:01,709 [INFO] Completed check: Balance non-negative\n",
      "2025-08-23 18:54:01,710 [INFO] Starting check: NumOfProducts range\n",
      "2025-08-23 18:54:01,710 [INFO] Completed check: NumOfProducts range\n",
      "2025-08-23 18:54:01,710 [INFO] Starting check: HasCrCard binary values\n",
      "2025-08-23 18:54:01,711 [INFO] Completed check: HasCrCard binary values\n",
      "2025-08-23 18:54:01,711 [INFO] Starting check: IsActiveMember binary values\n",
      "2025-08-23 18:54:01,712 [INFO] Completed check: IsActiveMember binary values\n",
      "2025-08-23 18:54:01,712 [INFO] Starting check: Exited binary values\n",
      "2025-08-23 18:54:01,713 [INFO] Completed check: Exited binary values\n",
      "2025-08-23 18:54:01,713 [INFO] Starting check: EstimatedSalary outliers\n",
      "2025-08-23 18:54:01,714 [WARNING] EstimatedSalary anomalies detected: 10 rows\n",
      "2025-08-23 18:54:01,714 [INFO] Completed check: EstimatedSalary outliers\n",
      "2025-08-23 18:54:01,733 [INFO] Issues report saved at datavalidation/reports/churn_data_issues_20250823_185401.csv\n",
      "2025-08-23 18:54:01,733 [INFO] Metadata report saved at datavalidation/reports/churn_data_metadata_20250823_185401.csv\n",
      "2025-08-23 18:54:01,734 [INFO] PDF report saved at datavalidation/reports/churn_data_report_20250823_185401.pdf\n",
      "2025-08-23 18:54:01,734 [INFO] ===== Validation completed =====\n",
      "2025-08-23 18:54:01,734 [INFO] Starting preprocessing and EDA...\n",
      "2025-08-23 18:54:01,735 [INFO] Handling missing values...\n",
      "2025-08-23 18:54:01,739 [INFO] Encoding categorical string variables...\n",
      "2025-08-23 18:54:01,745 [INFO] Normalizing continuous numeric attributes...\n",
      "2025-08-23 18:54:01,748 [INFO] Generating summary statistics...\n",
      "2025-08-23 18:54:01,757 [INFO] Creating EDA visualizations and saving to PDF...\n",
      "2025-08-23 18:54:02,133 [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-08-23 18:54:02,143 [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-08-23 18:54:02,224 [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-08-23 18:54:02,236 [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-08-23 18:54:02,316 [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-08-23 18:54:02,326 [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-08-23 18:54:02,401 [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-08-23 18:54:02,406 [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-08-23 18:54:02,670 [INFO] Preprocessing and EDA completed. Cleaned data saved at datapreparation/prepared/cleaned_data_20250823_185402.csv\n",
      "2025-08-23 18:54:02,671 [INFO] EDA PDF report saved at datapreparation/prepared/eda_report_20250823_185401.pdf\n",
      "2025-08-23 18:54:02,671 [INFO] Starting data transformation...\n",
      "2025-08-23 18:54:02,672 [INFO] Dropped columns: ['RowNumber', 'Surname']\n",
      "2025-08-23 18:54:02,672 [INFO] Creating new features...\n",
      "2025-08-23 18:54:02,675 [INFO] Feature engineering completed.\n",
      "2025-08-23 18:54:02,696 [INFO] Data successfully stored in SQLite: datatransformationandstorage/transformationandstorage/churn\n",
      "2025-08-23 18:54:02,698 [INFO] SQL schema design saved at datatransformationandstorage/transformationandstorage/schema_design_20250823_185402.sql\n",
      "2025-08-23 18:54:02,699 [INFO] Sample SQL queries saved at datatransformationandstorage/transformationandstorage/sample_queries.sql\n",
      "2025-08-23 18:54:02,710 [INFO] Query outputs saved at datatransformationandstorage/transformationandstorage/sample_query_outputs.txt\n",
      "2025-08-23 18:54:02,711 [INFO] Transformation summary saved at datatransformationandstorage/transformationandstorage/transformation_summary.txt\n",
      "2025-08-23 18:54:02,712 [INFO] Engineering features for feature store...\n",
      "2025-08-23 18:54:02,744 [INFO] Feature documentation generated at featurestore/featurestore/feature_documentation.md\n",
      "2025-08-23 18:54:02,744 [INFO] Feature store created at featurestore/featurestore/feature_store.db\n",
      "2025-08-23 18:54:02,753 [INFO] Sample queries saved at featurestore/featurestore/sample_queries.txt\n",
      "2025-08-23 18:54:02,754 [INFO] Query results saved at featurestore/featurestore/query_results.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 65e1cb0] Dataset update: churn_raw.csv (raw + transformed) - Changes_Commited\n",
      " 22 files changed, 10656 insertions(+), 735 deletions(-)\n",
      " create mode 100644 datapreparation/prepared/cleaned_data_20250823_185402.csv\n",
      " create mode 100644 datapreparation/prepared/eda_report_20250823_185401.pdf\n",
      " create mode 100644 datatransformationandstorage/transformationandstorage/schema_design_20250823_185402.sql\n",
      " create mode 100644 datavalidation/reports/churn_data_issues_20250823_185401.csv\n",
      " create mode 100644 datavalidation/reports/churn_data_metadata_20250823_185401.csv\n",
      " create mode 100644 datavalidation/reports/churn_data_report_20250823_185401.pdf\n",
      " create mode 100644 modelbuild/.ipynb_checkpoints/ModelBuild-checkpoint.ipynb\n",
      " rename {modelbuilding => modelbuild}/.ipynb_checkpoints/Untitled-checkpoint.ipynb (82%)\n",
      " create mode 100644 modelbuild/ModelBuild.ipynb\n",
      " rename {modelbuilding => modelbuild}/ModelBuild.py (75%)\n",
      " rename {modelbuilding => modelbuild}/Untitled.ipynb (82%)\n",
      " create mode 100644 modelbuild/__pycache__/ModelBuild.cpython-312.pyc\n",
      " delete mode 100644 modelbuilding/.ipynb_checkpoints/ModelBuild-checkpoint.ipynb\n",
      " delete mode 100644 modelbuilding/ModelBuild.ipynb\n",
      " delete mode 100644 modelbuilding/ModelBuilding.py\n",
      " delete mode 100644 modelbuilding/__pycache__/ModelBuilding.cpython-312.pyc\n",
      "[main c038802] Update version metadata for churn_raw.csv\n",
      " 1 file changed, 10 insertions(+)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/dhairyas87/dmml-bank-churn-pipeline\n",
      " * branch            main       -> FETCH_HEAD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current branch main is up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/dhairyas87/dmml-bank-churn-pipeline.git\n",
      "   8cc708d..c038802  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Raw + Transformed datasets for churn_raw.csv saved, versioned, and pushed under commit 65e1cb0542e15d94ab2b26d032e31bfd8ef60e9b\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM features': no such table: features",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: features",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     run_training(db_path)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[1], line 62\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     60\u001b[0m save_and_version_both(df_csv, df_feature,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataversioning/raw/churn_raw.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataversioning/transformed/churn_transformed_v1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchurn_raw.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChanges_Commited\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m run_training(db_path)\n",
      "File \u001b[0;32m~/DMML_Machine_Learning_Pipeline/modelbuild/ModelBuild.py:62\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(db_path)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_training\u001b[39m(db_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeaturestore/featurestore/feature_store.db\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 62\u001b[0m     df \u001b[38;5;241m=\u001b[39m load_features_from_store(db_path)\n\u001b[1;32m     64\u001b[0m     X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExited\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     65\u001b[0m     y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExited\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/DMML_Machine_Learning_Pipeline/modelbuild/ModelBuild.py:26\u001b[0m, in \u001b[0;36mload_features_from_store\u001b[0;34m(db_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_features_from_store\u001b[39m(db_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeaturestore/featurestore/feature_store.db\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     25\u001b[0m     conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(db_path)\n\u001b[0;32m---> 26\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM features\u001b[39m\u001b[38;5;124m\"\u001b[39m, conn)\n\u001b[1;32m     27\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    527\u001b[0m         sql,\n\u001b[1;32m    528\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m    529\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    530\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m    531\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m    532\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    533\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    534\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    535\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2729\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[1;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2686\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM features': no such table: features"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import dataingestion.DataIngestion\n",
    "import datastorage.DataStorage\n",
    "import datavalidation.DataValidation\n",
    "import datapreparation.DataPreparation\n",
    "import datatransformationandstorage.DataTransformationAndStorage\n",
    "import featurestore.FeatureStore\n",
    "import dataversioning.DataVersioning\n",
    "import modelbuild.ModelBuild\n",
    "\n",
    "importlib.reload(dataingestion.DataIngestion)\n",
    "importlib.reload(datastorage.DataStorage)\n",
    "importlib.reload(datavalidation.DataValidation)\n",
    "importlib.reload(datapreparation.DataPreparation)\n",
    "importlib.reload(datatransformationandstorage.DataTransformationAndStorage)\n",
    "importlib.reload(featurestore.FeatureStore)\n",
    "importlib.reload(dataversioning.DataVersioning)\n",
    "importlib.reload(modelbuild.ModelBuild)\n",
    "\n",
    "\n",
    "\n",
    "from dataingestion.DataIngestion import load_csv, load_api, load_db\n",
    "from datastorage.DataStorage import save_csv_or_db, save_api\n",
    "from datavalidation.DataValidation import validate_churn_data\n",
    "from datapreparation.DataPreparation import preprocess_and_eda\n",
    "from datatransformationandstorage.DataTransformationAndStorage import transform_and_store\n",
    "from featurestore.FeatureStore  import create_feature_store,sample_feature_queries\n",
    "from dataversioning.DataVersioning import save_and_version_both\n",
    "from modelbuild.ModelBuild import run_training\n",
    "\n",
    "\n",
    "def main():\n",
    "   \n",
    "\n",
    "    # CSV example\n",
    "    csv_url = \"https://synapseaisolutionsa.z13.web.core.windows.net/data/bankcustomerchurn/churn.csv\"\n",
    "    df_csv = load_csv(csv_url,csv_url)\n",
    "\n",
    "    base_dir = \"datastorage\"\n",
    "    save_csv_or_db(df_csv, base_dir, \"csv\")\n",
    "\n",
    "    base_dir = \"datavalidation/reports\"\n",
    "    issues, metadata = validate_churn_data(df_csv,base_dir,\"pdf\")\n",
    "\n",
    "    base_dir = \"datapreparation/prepared\"\n",
    "    df_processed = preprocess_and_eda(df_csv,base_dir) \n",
    "\n",
    "    base_dir = \"datatransformationandstorage/transformationandstorage\"\n",
    "    df_txfnstr = transform_and_store(df_processed,base_dir,\"churn\")\n",
    "\n",
    "    base_path = \"featurestore/featurestore\"   # <<< define your path here\n",
    "    df_feature,conn, db_path = create_feature_store(df_txfnstr, base_path)\n",
    "\n",
    "    # Run demo queries\n",
    "    sample_feature_queries(conn, base_path)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "    save_and_version_both(df_csv, df_feature,\"dataversioning/raw/churn_raw.csv\", \"dataversioning/transformed/churn_transformed_v1.csv\", \"churn_raw.csv\", \"Changes_Commited\")\n",
    "\n",
    "    run_training(db_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cac164-549a-4576-8c35-3bbef411696b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde366d-2b45-4c06-99fa-c54613f46171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c53d39-40be-406a-a206-f20604b27412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
